{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chapter3-9",
      "provenance": [],
      "authorship_tag": "ABX9TyObPJcX4EU2P084u1GOrmyE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ronniesong0809/Dive-into-Deep-Learning/blob/master/chapter3_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gV_pL4HoOX8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0198c4a0-215d-4971-dbf8-8f1a94cf8517"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import sys\n",
        "__version__ = '0.0.1'\n",
        "print(tf.__version__)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1u9sfbMpJa7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "batch_size = 256\n",
        "x_train = tf.cast(x_train, tf.float32)\n",
        "x_test = tf.cast(x_test, tf.float32)\n",
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0\n",
        "train_iter = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size)\n",
        "test_iter = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLrtIDKhpK-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_inputs, num_outputs, num_hiddens = 784, 10, 256\n",
        "W1 = tf.Variable(tf.random.normal(shape=(num_inputs, num_hiddens),mean=0, stddev=0.01, dtype=tf.float32))\n",
        "b1 = tf.Variable(tf.zeros(num_hiddens, dtype=tf.float32))\n",
        "W2 = tf.Variable(tf.random.normal(shape=(num_hiddens, num_outputs),mean=0, stddev=0.01, dtype=tf.float32))\n",
        "b2 = tf.Variable(tf.random.normal([num_outputs], stddev=0.1))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsSs5Y-Kp8SR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def relu(x):\n",
        "    return tf.math.maximum(x,0)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPfrpc6zp9S9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def net(X):\n",
        "    X = tf.reshape(X, shape=[-1, num_inputs])\n",
        "    h = relu(tf.matmul(X, W1) + b1)\n",
        "    return tf.math.softmax(tf.matmul(h, W2) + b2)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vo2tGRl6p-W1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(y_hat,y_true):\n",
        "    return tf.losses.sparse_categorical_crossentropy(y_true,y_hat)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIbbQGWvqKGs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, params=None, lr=None, trainer=None):\n",
        "    for epoch in range(num_epochs):\n",
        "        train_l_sum, train_acc_sum, n = 0.0, 0.0, 0\n",
        "        for X, y in train_iter:\n",
        "            with tf.GradientTape() as tape:\n",
        "                y_hat = net(X)\n",
        "                l = tf.reduce_sum(loss(y_hat, y))\n",
        "            grads = tape.gradient(l, params)\n",
        "            if trainer is None:\n",
        "                for i, param in enumerate(params):\n",
        "                    param.assign_sub(lr * grads[i] / batch_size)\n",
        "            else:\n",
        "                trainer.apply_gradients(zip([grad / batch_size for grad in grads], params))  \n",
        "                \n",
        "            y = tf.cast(y, dtype=tf.float32)\n",
        "            train_l_sum += l.numpy()\n",
        "            train_acc_sum += tf.reduce_sum(tf.cast(tf.argmax(y_hat, axis=1) == tf.cast(y, dtype=tf.int64), dtype=tf.int64)).numpy()\n",
        "            n += y.shape[0]\n",
        "        test_acc = evaluate_accuracy(test_iter, net)\n",
        "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f'% (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRCpW-yKqSk4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_accuracy(data_iter, net):\n",
        "    acc_sum, n = 0.0, 0\n",
        "    for _, (X, y) in enumerate(data_iter):\n",
        "        y = tf.cast(y,dtype=tf.int64)\n",
        "        acc_sum += np.sum(tf.cast(tf.argmax(net(X), axis=1), dtype=tf.int64) == y)\n",
        "        n += y.shape[0]\n",
        "    return acc_sum / n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfevhwcLp_UM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "e5d9e049-69eb-43fc-c955-7761c293bcd8"
      },
      "source": [
        "num_epochs, lr = 5, 0.5\n",
        "params = [W1, b1, W2, b2]\n",
        "train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, params, lr)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1, loss 0.4854, train acc 0.820, test acc 0.820\n",
            "epoch 2, loss 0.4214, train acc 0.843, test acc 0.848\n",
            "epoch 3, loss 0.3883, train acc 0.855, test acc 0.854\n",
            "epoch 4, loss 0.3663, train acc 0.864, test acc 0.862\n",
            "epoch 5, loss 0.3479, train acc 0.871, test acc 0.862\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}